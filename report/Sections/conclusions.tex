\section{Conclusions}
In this homework, we have implemented the QTAR algorithm and compared it to the algorithms of the previous homework.
The results show that the QTAR algorithm is not performing as well as the Q-Learning algorithm or the Georouting algorithm.
This is because in our problem we know the exact position of the destination (the depot) and we know that this position won't change during simulation.
QTAR algorithm in fact has been developed to achieve a different task, which is to find the best path to reach a destination drone that is moving.

Future developments may include:
\begin{itemize}
    \item 3D simulation or larger 2D environment
    \item Variable drone destination instead of fixed depot.
    \item Better simulation and failures on the second layer of the network.
\end{itemize}